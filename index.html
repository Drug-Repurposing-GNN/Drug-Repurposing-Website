<!DOCTYPE html>
<html>
<head>
    <title>FlyKD</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="icon" type="image/x-icon" href="/Images/pill.svg">
    <script type="text/javascript" src="app.js"></script>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
    <!-- <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> -->
    <script src="https://cdn.plot.ly/plotly-2.30.0.min.js"></script>
</head>
<body>
    <button class="back-button" onclick="slideDown()"> < Back </button>
    <div id="overviewText" class="overlay-text">
        <div id="overviewBackground"></div>
        <h2>Overview:</h2>
        <p> This project introduces FlyKD, a novel advancement in the field of biomedical research, 
            particularly focusing on enhancing drug-disease link prediction within biomedical knowledge graphs like PrimeKG. 
            By innovatively integrating Knowledge Distillation (KD) with Curriculum Learning in Graph Neural Networks (GNNs), 
            FlyKD aims to set new benchmarks in predictive modeling accuracy and efficiency. 
            This approach not only leverages the foundation laid by previous GNN and KD methodologies 
            but also introduces novel computational strategies to address the challenges of model optimization over noisy pseudo labels. 
            The synergy between these technologies promises to revolutionize the analysis of complex biomedical data, 
            facilitating significant strides in precision medicine and drug repurposing.
        </p>
        <p>
            This advancement promises to accelerate research in precision medicine and drug repurposing, 
            leveraging the strengths of TxGNN as a base while introducing novel computational strategies. 
            The collaboration of these technologies is set to transform the analysis of complex biomedical data, 
            facilitating a deeper understanding of disease mechanisms and broadening the horizons for therapeutic discovery.
        </p>
        <h2>PrimeKG:</h2>
        <p> 
            PrimeKG is a sophisticated biomedical knowledge graph that serves as a critical foundation for this project, 
            integrating an extensive range of biomedical data. It encompasses genomic information, protein interactions, 
            chemical properties, and disease associations, providing a comprehensive framework for advanced research in drug discovery 
            and precision medicine. By leveraging PrimeKG, the project taps into a rich resource of interconnected data, 
            enabling the exploration of complex biological relationships and facilitating the development of innovative 
            approaches to predictive modeling in the biomedical field.
        </p>
        
        <h2>TxGNN:</h2>
        <p> TxGNN, pivotal in our project, harnesses Graph Neural Networks to delve into PrimeKG's rich biomedical data, 
            aiming for breakthroughs in drug-disease link prediction. Its architecture is strategically designed to uncover 
            new drug applications and elucidate disease pathways, marking a significant leap toward advancing precision medicine. 
            This model not only propels our understanding of complex biological interactions 
            but also sets the stage for innovative drug discovery and repurposing initiatives.
        </p>
        <h2>Knowledge Distillation and FlyKD:</h2>
        <p> 
            FlyKD represents a cutting-edge approach to Knowledge Distillation (KD) within the realm of GNNs, 
            focusing on the biomedical domain. It transcends traditional KD techniques by generating an unlimited number of pseudo labels on-the-fly, 
            effectively overcoming memory limitations and enhancing model training efficiency. 
            Incorporating Curriculum Learning, FlyKD meticulously tackles the optimization challenges posed by noisy pseudo labels, 
            improving the model's learning curve and accuracy. This methodological innovation not only elevates the predictive modeling capabilities of 
            GNNs in biomedical research but also opens up new avenues for exploring drug-disease interactions, 
            with the potential to significantly impact therapeutic discovery and development.
        </p>
        
        <button class="section-nav-button" id="toMethodsButton" onclick="switchSection('methodsText', 'method-text')">Methods &gt;</button>

    </div>
    <div id="methodsText" class="method-text">
        <div id="methodsBackground"></div>
        <h2>Methods:</h2>
        <p> Our approach begins by training a TxGNN model on labeled data to construct a robust teacher model, 
            which generates pseudo labels via Knowledge Distillation, thereby expanding our dataset. 
            Following this, a second TxGNN model is trained using both the original and pseudo-labeled data, 
            introducing noise elements like VGAE and Dropout to simulate complex learning scenarios. This cycle repeats, 
            refining the model with each iteration until reaching optimal stability. </p>
        <img src="Images/Labels.png" alt="Model Architecture" style="width: 40%; height: auto;">
        <p> Simultaneously, we introduce FlyKD, a novel framework that produces a vast number of pseudo labels on-the-fly, 
            overcoming traditional memory constraints. It utilizes Curriculum Learning to manage the pseudo labels' inherent noisiness effectively. 
            FlyKD creates random graphs each epoch, applying the DistMult scoring function to foster the student model's global imitation 
            of the teacher model. This iterative process, enriched with a linear loss scheduler, 
            optimizes the model's exposure to progressively complex labels, setting new standards in graph-based predictive modeling. </p>

        <h2>Resutls:</h2>
        
        <!-- <canvas id="resultsChart"></canvas> -->
        <div id='myDiv'><!-- Plotly chart will be drawn inside this DIV --></div>
        <p>
            In our study, we delve into three distinct methods of Knowledge Distillation (KD) for Graph Neural Networks (GNN): 
            Basic Knowledge Distillation (BKD) as introduced by Hinton, Vinyals, and Dean in 2015, 
            Local Structure Preserving GCN (LSPGCN, also known as DistillGCN) developed by Yang et al. in 2020, 
            and our innovative approach, FlyKD. Our analysis reveals that while BKD and LSPGCN unfortunately result in diminished KD effects, 
            FlyKD stands out by achieving positive advancements beyond the foundational model, which did not incorporate KD techniques, 
            starting from a baseline of 80.
        </p>

        <div id='myDiv2'><!-- Plotly chart will be drawn inside this DIV --></div>

        <p>
            Through a comprehensive ablation study, we uncover that the disparity between FlyKD's performance 
            and that of other KD strategies can be attributed to the influence of noise in the pseudo labels generated by the teacher model. 
            Remarkably, when we integrate Curriculum Learning into the BKD framework, we witness a significant enhancement in its efficacy, 
            with a performance increase of +1.55% compared to its implementation without Curriculum Learning.
        </p>
        <button class="section-nav-button" id="toOverviewButton" onclick="switchSection('overviewText', 'overlay-text')">&lt; Overview</button>
    </div>
    <div class="main-container bg-image">
        <div class="centered-container">
            <div id="title-div">
                <h1 id="title">FlyKD</h1> <h1>Graph Knowledge Distillation on the Fly with Curriculum Learning</h1>
            </div>
            
            <div class="button-container">
                <button class="text-button" onclick="slideUp('overviewText', 'overlay-text')">Overview</button>
                <button class="text-button" onclick="slideUp('methodsText', 'method-text')">Methods</button>
                <button href="https://github.com/Drug-Repurposing-GNN/SSL-DiseaseDrug-Prediction" class="text-button" onclick="window.open('https://github.com/Drug-Repurposing-GNN/SSL-DiseaseDrug-Prediction')">Code</button>
            </div>
        </div>
    </div>
</body>
</html>