<!DOCTYPE html>
<html>
<head>
    <title>FlyKD</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="icon" type="image/x-icon" href="/Images/pill.svg">
    <script type="text/javascript" src="app.js"></script>
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
    <!-- <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> -->
    <script src="https://cdn.plot.ly/plotly-2.30.0.min.js"></script>
</head>
<body>
    <button class="back-button" onclick="slideDown()"> < Back </button>
    <div id="overviewText" class="overlay-text">
        <div id="overviewBackground"></div>
        <h2>Overview:</h2>
        <p> We propose FlyKD, a novel, scalable way to compress large Graph Neural Networks
            (GNN) to lighter, deployable GNNs. Specifically, FlyKD is a variation of Knowledge
            Distillation (KD) method where a larger, more capable teacher model generates
            pseudo labels for the student model to learn from. 
        </p>
        <p>
            FlyKD has two novel components in addition to the original KD to address two problems
            in Knowledge Distillation in Graphs. The first problem FlyKD addresses is memory isssue of 
            GNNs. When you generate many pseudo labels using GNNs, users will often run into cuda 
            Out of Memory (OOM) issue as the student model backpropagates. However,
            by generating unseen pseudo labels on the fly with randomness at every epoch, one can generate
            virtually infinite amount of pseudo labels for the student model to learn from. 
        </p>
        <p>
            But this poses another problem: pseudo labels are inherently noisy and difficult to optimize.
            Generating immense amount of pseudo labels worsens this problem. In order to alleviate this,
            FlyKD incorporates a form of Curriculum Learning. Inspired by how humans learn, Curriculum 
            Learning helps the optimization process of the model by introducing data at an increasing
            complexity. To incoporate Curriculum Learning, we use our prior knowledge of noisiness
            of each type of labels and gradually introduce them in the order of noisiness. 
        </p>
        <h2>PrimeKG:</h2>
        <p> 
            Our dataset is composed of the latest biomedical Knowledge Graph called Precision Medicine
            Knowledge Graph (Chandak, Huang and Zitnik (2023)), which combines 20+ credible databases such 
            as DrugBank, DrugCentral, DisGeNet, etc. PrimeKG is specially designed for therepeutic 
            repurposing of drugs and can be used to find new treatments to diseases that currently 
            have no treatment. 
        </p>
        <p> 
            Furthermore, PrimeKG has over 4 million relations and the scheme of the Knowledge Graph can be illustrated 
            below (adapted from Chandak, Huang and Zitnik (2023)):
            <div style="text-align: center;">
                <img src="Images/schematic-nobg.png" height: auto;">
            </div>
        </p>
        <div class="nav-button-container ">
        <button class="section-nav-button" id="toMethodsButton" onclick="switchSection('methodsText', 'method-text')">Methods &gt;</button>
        </div>
    </div>
    <div id="methodsText" class="method-text">
        <div id="methodsBackground"></div>
        <h2>Methods:</h2>
        <p> FlyKD first trains a teacher TxGNN, zero-shot Relational GCN (R-GCN) developed by (Chandak, Huang and Zitnik
(2023)), 
            to predict the existence of indication and contraindication relations between drugs and diseases. With
            pre-trained teacher TxGNN, we obtain the final node embeddings of the original graph then use the final node embeddings
            with a scoring function called DistMult to generate three types of labels: Original Label, Pseudo label on Training graph,
            and Pseudo label on Degree-aware Random Graph. These three types of labels are illustrated below and ordered by the 
            level of noisiness. </p>
        <img src="Images/Labels.png" alt="Model Architecture" height: auto;">
        <p>
            The recipe for generating Degree-Aware Random Graph is depicted below: 
        </p>

        <img src="Images/Algo.png" height: auto;">
        <p>
            In plain words, GenerateRandomGraph selects two nodes where the probability of a
            node being selected is proportionate to the degree of a node in the original graph (with
            respect to the relation). By doing so, we increase the quality of the pseudo labels on the
            random graph by utilizing the prior information that nodes that have seen more labels
            during training are more likely to have a higher embedding quality. Once two nodes are
            selected, a link is formed between them. This process of generating pseudo links is repeated
            k times.
        </p>
        <p>
            The above generation of random graph per epoch conceptually enables the teacher model to generate
            unlimited number of pseudo labels that can be backpropgated by the student model. 
        </p>
        <p>
            As mentioned earlier, pseudo labels are inherently noisy and pseudo labels on random graphs are 
            even more noisy. Thus, we incorporate a form of Curriculum Learning by utilizing a loss scheduler,
            which gradually shifts the emphasis from easy original label to medium pseudo label on train graph and
            ultimately hard pseudo label on the random graph. The loss scheduler is depicted below:
        </p>
        
        <img src="Images/scheduler.png" height: auto;">
        <br>
        <div class="nav-button-container ">
        <button class="section-nav-button" id="toOverviewButton" onclick="switchSection('overviewText', 'overlay-text')">&lt; Overview</button>
        
        <button class="section-nav-button" id="toMethodsButton" onclick="switchSection('resultsText', 'method-text')">Results &gt;</button>    
        </div>
    </div>
    <div id="resultsText" class="method-text">
        <div id="methodsBackground"></div>
            <h2>Results:</h2>
            <p>
                Here are the baseline models' performances where TxGNN 130 represents the more capable teacher model and 
                TxGNN 80 represents the lighter student model.
            </p>
            <table style="width:75%; margin: auto; border-collapse: collapse; border: 1px solid black; margin-bottom: 20px;">
                <caption style="text-align: center; font-weight: bold; margin-bottom: 0.5em;">
                    Baseline AUPRC (%):
                </caption>
                <tr>
                    <th style="border: 1px solid black;">Model</th>
                    <th style="border: 1px solid black;">Num. Params</th>
                    <th style="border: 1px solid black;">Seed 45</th>
                    <th style="border: 1px solid black;">Seed 46</th>
                    <th style="border: 1px solid black;">Seed 47</th>
                    <th style="border: 1px solid black;">Seed 48</th>
                    <th style="border: 1px solid black;">Seed 49</th>
                    <th style="border: 1px solid black;">Mean ± std</th>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">Baseline 130</td>
                    <td style="border: 1px solid black;">(1.7M)</td>
                    <td style="border: 1px solid black;">80.33</td>
                    <td style="border: 1px solid black;">73.66</td>
                    <td style="border: 1px solid black;">76.29</td>
                    <td style="border: 1px solid black;">84.19</td>
                    <td style="border: 1px solid black;">79.91</td>
                    <td style="border: 1px solid black;">78.87 ± 4.04</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">Baseline 80</td>
                    <td style="border: 1px solid black;">(650k)</td>
                    <td style="border: 1px solid black;">78.64</td>
                    <td style="border: 1px solid black;">71.97</td>
                    <td style="border: 1px solid black;">74.44</td>
                    <td style="border: 1px solid black;">82.74</td>
                    <td style="border: 1px solid black;">77.87</td>
                    <td style="border: 1px solid black;">77.13 ± 4.13</td>
                </tr>
            </table>
            <p>
                There is a high variance of performance due to zero-shot
                evaluation setting. Thus, we focus on the relative performance gains at each seed and average across seeds. 
                This way, we can more accurately attribute changes in performance to the methods themselves, 
                rather than to fluctuations in task difficulty associated with different seeds.
            </p>
    
            <p>
                In our study, we delve into three distinct methods of Knowledge Distillation (KD) for Graph Neural Networks (GNN): 
                Basic Knowledge Distillation (BKD) as introduced by Hinton, Vinyals, and Dean in 2015, 
                Local Structure Preserving GCN (LSPGCN, also known as DistillGCN) developed by Yang et al. in 2020, 
                and our innovative approach, FlyKD.
            </p>
            <table style="width:75%; margin: auto; border-collapse: collapse; border: 1px solid black; margin-bottom: 20px;">
                <caption style="text-align: center; font-weight: bold; margin-bottom: 0.5em;">
                    Knowledge Distillation Methods (Relative gains from Baseline80)
                </caption>
                <tr>
                    <th style="border: 1px solid black;">Model</th>
                    <th style="border: 1px solid black;">Time</th>
                    <th style="border: 1px solid black;">Curriculum Learning</th>
                    <th style="border: 1px solid black;">Mean±std</th>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">Basic KD</td>
                    <td style="border: 1px solid black;">1600</td>
                    <td style="border: 1px solid black;">No</td>
                    <td style="border: 1px solid black;">-0.62±0.59</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">LSP 1 layer (RBF)</td>
                    <td style="border: 1px solid black;">20000</td>
                    <td style="border: 1px solid black;">No</td>
                    <td style="border: 1px solid black;">-1.09±0.23</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">LSP 2 layers (RBF)</td>
                    <td style="border: 1px solid black;">40000</td>
                    <td style="border: 1px solid black;">No</td>
                    <td style="border: 1px solid black;">-1.41±0.82</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">FlyKD</td>
                    <td style="border: 1px solid black;">2000</td>
                    <td style="border: 1px solid black;">Yes</td>
                    <td style="border: 1px solid black;">1.16±0.36</td>
                </tr>
            </table>
    
            <p>
                Our experiments reveal that while BKD and LSPGCN result in negative KD effects, 
                FlyKD stands out by achieving positive relative gains. We find out the reason for such gap in the following
                ablation study.
            </p>
            
<!--             <div id='myDiv2'></div> -->
            <table style="width:75%; margin-left: auto; margin-right: auto; border-collapse: collapse; border: 1px solid black; margin-bottom: 20px;">
                <caption style="text-align: center; font-weight: bold; margin-bottom: 0.5em;">
                    Ablation study (Relative gains from Baseline80)
                </caption>
                <tr>
                    <th style="border: 1px solid black;">Model</th>
                    <th style="border: 1px solid black;">Configuration</th>
                    <th style="border: 1px solid black;">Mean±std</th>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">Basic KD</td>
                    <td style="border: 1px solid black;">Employ Curriculum Learning</td>
                    <td style="border: 1px solid black;">0.93±0.45</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">FlyKD</td>
                    <td style="border: 1px solid black;">Fix Random Graph</td>
                    <td style="border: 1px solid black;">1.14±0.39</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">FlyKD</td>
                    <td style="border: 1px solid black;">No Curriculum Learning</td>
                    <td style="border: 1px solid black;">0.19±0.42</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">FlyKD</td>
                    <td style="border: 1px solid black;">Take Out Pseudo Labels on Train Dataset</td>
                    <td style="border: 1px solid black;">-0.68±0.63</td>
                </tr>
                <tr>
                    <td style="border: 1px solid black;">FlyKD</td>
                    <td style="border: 1px solid black;">stepwise function for Curriculum Learning</td>
                    <td style="border: 1px solid black;">-1.436±0.86</td>
                </tr>
            </table>
            <p>
                Our ablation study shows that noise in the teacher model's pseudo labels causes the performance gap between FlyKD and other KD methods. 
                Adding Curriculum Learning to BKD improves its performance noticeably, giving a +1.55% boost over the standard approach.
            </p>
        <div class="nav-button-container ">
        <button class="section-nav-button" id="toOverviewButton" onclick="switchSection('methodsText', 'method-text')">&lt; Methods</button>
        
        <button class="section-nav-button" id="toMethodsButton" onclick="switchSection('findingsText', 'method-text')">Findings &gt;</button>    
        </div>
    </div>
    <div id="findingsText" class="method-text">
        <div id="methodsBackground"></div>
        <h2>Findings</h2>
        <ul>
            <li>Optimization process of the student model in KD is inherently noisy, and Curriculum Learning can greatly alleviate this issue.</li>
            <li>Curriculum Learning for KD requires a gradual change in difficulty, corroborated by catastrophic degradation in performance when a step-wise loss scheduler is employed instead.</li>
            <li>LSPGCN is not scalable for Knowledge Graphs, as demonstrated by a 10-20x increase in time as shown in Table 2. This holds true for most Knowledge Distillation methods tailored for graphs with similar mechanisms.</li>
            <li>FlyKD’s pseudo labels on degree-aware random graphs seem to help but do not provide any additional gains beyond the generation of one random graph and maintaining it, instead of generating a new random graph at every epoch throughout the training. Further investigation is needed to understand this phenomenon.</li>
        </ul>
        <p>
            Last Remark:
            We believe our experimental results suggest a new research direction of how to improve the
            optimization process of the student model rather than the common what pseudo labels to
            generate (What to distill).
        </p>
        <div class="nav-button-container ">
        <button class="section-nav-button" id="toOverviewButton" onclick="switchSection('resultsText', 'method-text')">&lt; Results</button>
        </div>
    </div>
        
    <div class="main-container bg-image">
        <div class="centered-container">
            <div id="title-div">
                <h1 id="title">FlyKD</h1> <h1>Graph Knowledge Distillation on the Fly with Curriculum Learning</h1>
            </div>
            
            <div class="button-container">
                <button class="text-button" onclick="slideUp('overviewText', 'overlay-text')">Overview</button>
                <button class="text-button" onclick="slideUp('methodsText', 'method-text')">Methods</button>
                <button class="text-button" onclick="slideUp('resultsText', 'method-text')">Results</button>
                <button class="text-button" onclick="slideUp('findingsText', 'method-text')">Findings</button>
                <button href="https://github.com/Drug-Repurposing-GNN/SSL-DiseaseDrug-Prediction" class="text-button" onclick="window.open('https://github.com/Drug-Repurposing-GNN/SSL-DiseaseDrug-Prediction')">Code</button>
                <button href="https://drive.google.com/file/d/148UQyEkZ6p4ZGRXUR3hh5w5m7xPlSrUP/view?usp=sharing" class="text-button" onclick="window.open('https://drive.google.com/file/d/148UQyEkZ6p4ZGRXUR3hh5w5m7xPlSrUP/view?usp=sharing')">Paper</button>
            </div>
        </div>
    </div>
</body>
</html>
